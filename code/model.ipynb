{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HDcJ05LXm1S",
        "colab_type": "text"
      },
      "source": [
        "#**SUMMARY**\n",
        "\n",
        "Filename    : model.ipynb   \n",
        "Description : The file contains logic for creating model\n",
        "\n",
        "Below steps were performed for data preparation,   \n",
        "      1.   Building a pneumonia detection model starting from basic CNN and then   improving upon it.   \n",
        "      2.   Train the model     \n",
        "      3.   To deal with large training time, save the weights so that you can use them when training the model for the second time without starting from scratch.   \n",
        "\n",
        "\n",
        "**Revision History**  \n",
        "Date        ||       Description               ||              Author  \n",
        "07-06-2020   ||   Initial logic for model creation   ||   Arvindh   \n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvhRx5MRYiHa",
        "colab_type": "text"
      },
      "source": [
        "#**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZ4Jfrc8YSc4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHYQn7IXYSy6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "480045f1-a450-4389-dcf9-0576e04021b2"
      },
      "source": [
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa5yDwoJYbNy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "694faa2f-ebbe-43bc-ab63-dc510d279a6a"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from seaborn import countplot\n",
        "from matplotlib.pyplot import figure, show\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.patches import Rectangle\n",
        "import seaborn as sns"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z85yjH-RZRR3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18a059e4-b1b0-4a6c-ad3d-cd09d5bbb9a0"
      },
      "source": [
        "!pip3 install pydicom\n",
        "import pydicom\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "import keras\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import cv2"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQzsbUTrZX_3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import SGD, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4EqYTeKYdSy",
        "colab_type": "text"
      },
      "source": [
        "#Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3vVLc5MYfrr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0aa6214c-3265-44c0-ba41-81e86799d6c0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "io6GZGSFYqdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set your project path \n",
        "project_path =  'drive/My Drive/Colab Notebooks/Capstone'\n",
        "train_img_path = 'drive/My Drive/Colab Notebooks/Capstone/dataset/stage_2_train_images'\n",
        "valid_img_path = 'drive/My Drive/Colab Notebooks/Capstone/dataset/stage_2_train_images'\n",
        "test_img_path = 'drive/My Drive/Colab Notebooks/Capstone/dataset/stage_2_test_images'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "auaGzcAlaYy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df_pick = \"/train_df_pickle\"\n",
        "valid_df_pick = \"/valid_df_pickle\"\n",
        "\n",
        "# we open the file for reading\n",
        "fileObject = open(project_path+train_df_pick,'rb')  \n",
        "fileObject1 = open(project_path+valid_df_pick,'rb')  \n",
        "\n",
        "# load the object from the file into temp var b\n",
        "train_df = pickle.load(fileObject)  \n",
        "valid_df = pickle.load(fileObject1) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFWhWGKTi-_7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b60ced7-3ea7-411b-8386-714b5e0a46f2"
      },
      "source": [
        "train_patient_Ids = train_df.patientId.unique()\n",
        "print(\"The number of unique patient id in the training dataset is \"+ str(train_patient_Ids.shape[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique patient id in the training dataset is 21908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCNm18Nsjv1B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20f79466-d19b-4a65-dc3a-1001183fb2a2"
      },
      "source": [
        "valid_patient_Ids = valid_df.patientId.unique()\n",
        "print(\"The number of unique patient id in the validation dataset is \"+ str(valid_patient_Ids.shape[0]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of unique patient id in the validation dataset is 5914\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZATT1GkQblKx",
        "colab_type": "text"
      },
      "source": [
        "#Custom Data generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_4EBVvbjta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(keras.utils.Sequence):\n",
        "  def __init__(self, unique_patient_ids, folder, dataframe, batch_size=10, shuffle=False, image_size=256):\n",
        "        self.unique_patient_ids = unique_patient_ids\n",
        "        self.folder = folder\n",
        "        self.dataframe = dataframe\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.image_size = image_size\n",
        "        self.on_epoch_end()\n",
        "   \n",
        "  def __load__(self, pat_id):\n",
        "        patIdWithExt = pat_id+'.dcm'\n",
        "        # load dicom file from pixel array\n",
        "        img = pydicom.dcmread(os.path.join(self.folder, patIdWithExt)).pixel_array\n",
        "        # create empty array\n",
        "        msk = np.zeros(img.shape) \n",
        "        \n",
        "        if pat_id in self.dataframe[\"patientId\"].values:\n",
        "            pat_info = self.dataframe[self.dataframe.patientId == pat_id]\n",
        "\n",
        "            # loop through pat rows in the df\n",
        "            for info in pat_info.iterrows():\n",
        "                row = info[1]\n",
        "                if row.Target == 1:\n",
        "                    x = int(row.x)\n",
        "                    y = int(row.y)\n",
        "                    msk[y: int(row.y) + int(row.height), x: int(row.x) + int(row.width)] = 1 \n",
        "        '''\n",
        "        row = dataframe[1]\n",
        "        if row.Target == 1:\n",
        "            x = int(row.x)\n",
        "            y = int(row.y)\n",
        "            msk[y: int(row.y) + int(row.height), x: int(row.x) + int(row.width)] = 1  \n",
        "        '''\n",
        "        img = cv2.resize(img, (self.image_size, self.image_size))\n",
        "        msk = cv2.resize(msk, (self.image_size, self.image_size))\n",
        "        img = np.expand_dims(img, -1)\n",
        "        msk = np.expand_dims(msk, -1)   \n",
        "\n",
        "        #img2 = np.concatenate((img,)*3, axis=-1) \n",
        "        #msk2 = np.concatenate((msk,)*3, axis=-1)\n",
        "        return img, msk\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "        # select pat_ids by batches\n",
        "        batch_pat_ids = self.unique_patient_ids[index*self.batch_size : (index+1)*self.batch_size]\n",
        "\n",
        "        # load pat ids by loop\n",
        "        items = [self.__load__(pat_id_row) for pat_id_row in batch_pat_ids]\n",
        "        imgs, msks = zip(*items)\n",
        "\n",
        "        # create numpy batch\n",
        "        imgs = np.array(imgs)\n",
        "        msks = np.array(msks)\n",
        "        return imgs, msks\n",
        "\n",
        "  def __len__(self):\n",
        "    # __len__ provides number of batches per epoch\n",
        "    return int(np.floor(self.unique_patient_ids.shape[0] / self.batch_size))\n",
        "\n",
        "  def on_epoch_end(self):\n",
        "        self.indexes = np.arange(self.unique_patient_ids.shape[0])\n",
        "        if self.shuffle == True:\n",
        "              np.random.shuffle(self.indexes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti1eu2kpoC21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To be used finally\n",
        "#train_gen = Generator(train_patient_Ids, train_img_path, train_df, batch_size=32, shuffle=False, image_size=256)\n",
        "#valid_gen = Generator(valid_patient_Ids, valid_img_path, valid_df, batch_size=32, shuffle=False, image_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIElaIRStJWY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_gen = Generator(train_patient_Ids[:20], train_img_path, train_df, batch_size=10, shuffle=False, image_size=256)\n",
        "valid_gen = Generator(valid_patient_Ids[:10], valid_img_path, valid_df, batch_size=10, shuffle=False, image_size=256)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFln1i51pWCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_downsample(channels, inputs):\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n",
        "    x = keras.layers.MaxPool2D(2)(x)\n",
        "    return x\n",
        "\n",
        "def create_resblock(channels, inputs):\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(inputs)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
        "    return keras.layers.add([x, inputs])\n",
        "\n",
        "def create_network(input_size, channels, n_blocks=2, depth=4):\n",
        "    # input\n",
        "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
        "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n",
        "    # residual blocks\n",
        "    for d in range(depth):\n",
        "        channels = channels * 2\n",
        "        x = create_downsample(channels, x)\n",
        "        for b in range(n_blocks):\n",
        "            x = create_resblock(channels, x)\n",
        "    \n",
        "    x = keras.layers.BatchNormalization(momentum=0.9)(x)\n",
        "    x = keras.layers.LeakyReLU(0)(x)\n",
        "    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
        "    outputs = keras.layers.UpSampling2D(2**depth)(x)\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cosSGMXopKlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create network and compiler\n",
        "model = create_network(input_size=256, channels=32, n_blocks=2, depth=4)\n",
        "model.compile(optimizer='adam',loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yALWJUJo3rj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b22b8be0-fab6-4d4d-90a2-d710a1c77c2d"
      },
      "source": [
        "history = model.fit_generator(train_gen, validation_data=valid_gen, epochs=2, workers=4, use_multiprocessing=False)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "2/2 [==============================] - 36s 18s/step - loss: 0.7356 - accuracy: 0.9202 - val_loss: 12.4542 - val_accuracy: 0.1689\n",
            "Epoch 2/2\n",
            "2/2 [==============================] - 34s 17s/step - loss: 0.4717 - accuracy: 0.9441 - val_loss: 1.2096 - val_accuracy: 0.8847\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}